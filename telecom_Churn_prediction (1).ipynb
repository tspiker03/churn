{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prediction of customer churn of telecom company based on customer behavior"
      ],
      "metadata": {
        "id": "bOgLl6MzU01r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas_profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vydO64-ERE6i",
        "outputId": "513aa111-eacb-4ebe-8d5a-6b4d05fff105"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas_profiling\n",
            "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/324.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ydata-profiling (from pandas_profiling)\n",
            "  Downloading ydata_profiling-4.3.1-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.0/353.0 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.11,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.10.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.5.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.10.9)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (6.0)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (3.1.2)\n",
            "Collecting visions[type_image_path]==0.7.5 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (1.22.4)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (2.27.1)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (4.65.0)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.12.2)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling->pandas_profiling) (0.13.5)\n",
            "Collecting typeguard<3,>=2.13.2 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wordcloud>=1.9.1 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading wordcloud-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (455 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.4/455.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dacite>=1.8 (from ydata-profiling->pandas_profiling)\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling->pandas_profiling) (8.4.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling) (3.1)\n",
            "Collecting tangled-up-in-unicode>=0.0.4 (from visions[type_image_path]==0.7.5->ydata-profiling->pandas_profiling)\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas_profiling) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.2->ydata-profiling->pandas_profiling) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2.1,>1.1->ydata-profiling->pandas_profiling) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas_profiling) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling->pandas_profiling) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling->pandas_profiling) (3.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas_profiling) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling->pandas_profiling) (1.16.0)\n",
            "Building wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=8649f2c89b143322cc7a922e44dd1f2b9e8bb95e97409c0938404e1ec01ec397\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin, typeguard, tangled-up-in-unicode, multimethod, dacite, imagehash, wordcloud, visions, phik, ydata-profiling, pandas_profiling\n",
            "  Attempting uninstall: wordcloud\n",
            "    Found existing installation: wordcloud 1.8.2.2\n",
            "    Uninstalling wordcloud-1.8.2.2:\n",
            "      Successfully uninstalled wordcloud-1.8.2.2\n",
            "Successfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.9.1 pandas_profiling-3.6.6 phik-0.12.3 tangled-up-in-unicode-0.2.0 typeguard-2.13.3 visions-0.7.5 wordcloud-1.9.2 ydata-profiling-4.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alFDlJ6AQ5zn",
        "outputId": "81ba4139-6005-4634-da60-f1f6842bc3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2ff44370e261>:5: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
            "  import pandas_profiling\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import pandas_profiling\n",
        "import plotly.offline as po\n",
        "import plotly.graph_objects as go\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_profiling.ProfileReport(pd.read_csv('/train.csv'))"
      ],
      "metadata": {
        "id": "aUt_PHA_RDHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tele_dataset =  pd.read_csv(\"/train.csv\")\n",
        "tele_dataset.shape"
      ],
      "metadata": {
        "id": "d6FQNgphjEUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Columns: international play, voicemail plan and churn are boolean columns with yes, no answers.  we need to convert to 1,0"
      ],
      "metadata": {
        "id": "cDbJuphejdFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tele_dataset.loc[tele_dataset.churn=='no','churn'] = 0\n",
        "tele_dataset.loc[tele_dataset.churn=='yes','churn'] = 1\n",
        "tele_dataset.loc[tele_dataset.international_plan=='no','international_plan'] = 0\n",
        "tele_dataset.loc[tele_dataset.international_plan=='yes','international_plan'] = 1\n",
        "tele_dataset.loc[tele_dataset.voice_mail_plan=='no','voice_mail_plan'] = 0\n",
        "tele_dataset.loc[tele_dataset.voice_mail_plan=='yes','voice_mail_plan'] = 1"
      ],
      "metadata": {
        "id": "t13IX7VOjbcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that that's done, lets look at churn as a function of some of the other variables.  Correlation Matrices aren't perfect for showing exactly which variables are related to churn, but it can give us a ok place to start.  But first, lets look at the overall rate of Churn"
      ],
      "metadata": {
        "id": "uIObwwjoo7sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_by_churn_labels = tele_dataset[\"churn\"].value_counts().keys().tolist()\n",
        "plot_by_churn_values = tele_dataset[\"churn\"].value_counts().values.tolist()\n",
        "\n",
        "plot_data= [\n",
        "    go.Pie(labels = plot_by_churn_labels,\n",
        "           values = plot_by_churn_values,\n",
        "           marker = dict(colors =  [ 'Teal' ,'Grey'],\n",
        "                         line = dict(color = \"white\",\n",
        "                                     width =  1.5)),\n",
        "           rotation = 90,\n",
        "           hoverinfo = \"label+value+text\",\n",
        "           hole = .6)\n",
        "]\n",
        "plot_layout = go.Layout(dict(title = \"Customer Churn\",\n",
        "                   plot_bgcolor  = \"rgb(243,243,243)\",\n",
        "                   paper_bgcolor = \"rgb(243,243,243)\",))\n",
        "\n",
        "\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "po.iplot(fig)"
      ],
      "metadata": {
        "id": "fL0dqXF6qbj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tele_dataset['churn'].unique"
      ],
      "metadata": {
        "id": "Sel2PIjrr2ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_by_day_minutes = tele_dataset.groupby('total_day_minutes').churn.mean().reset_index()\n",
        "plot_data = [\n",
        "    go.Bar(\n",
        "        x=plot_by_day_minutes['total_day_minutes'],\n",
        "        y=plot_by_day_minutes['churn'],\n",
        "        width = [0.3, 0.3],\n",
        "        marker=dict(\n",
        "        color=['orange', 'green'])\n",
        "    )\n",
        "]\n",
        "plot_layout = go.Layout(\n",
        "        xaxis={\"type\": \"category\"},\n",
        "        yaxis={\"title\": \"Churn Rate\"},\n",
        "        title='Churn Rate by Total Daily Minutes',\n",
        "        plot_bgcolor  = 'rgb(243,243,243)',\n",
        "        paper_bgcolor  = 'rgb(243,243,243)',\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "po.iplot(fig)"
      ],
      "metadata": {
        "id": "6Uk_KmI8rF9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_by_cust_service = tele_dataset.groupby('number_customer_service_calls').churn.mean().reset_index()\n",
        "plot_data = [\n",
        "    go.Bar(\n",
        "        x=plot_by_cust_service['number_customer_service_calls'],\n",
        "        y=plot_by_cust_service['churn'],\n",
        "        width = [0.3, 0.3],\n",
        "        marker=dict(\n",
        "        color=['orange', 'green'])\n",
        "    )\n",
        "]\n",
        "plot_layout = go.Layout(\n",
        "        xaxis={\"type\": \"category\"},\n",
        "        yaxis={\"title\": \"Churn Rate\"},\n",
        "        title='Churn Rate by customer service calls',\n",
        "        plot_bgcolor  = 'rgb(243,243,243)',\n",
        "        paper_bgcolor  = 'rgb(243,243,243)',\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "po.iplot(fig)"
      ],
      "metadata": {
        "id": "Ot-57AxdQY8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_by_day_charge = tele_dataset.groupby('total_day_charge').churn.mean().reset_index()\n",
        "plot_data = [\n",
        "             go.Bar(\n",
        "                x=plot_by_day_charge['total_day_charge'],\n",
        "                y=plot_by_day_charge['churn'],\n",
        "                width = [0.3, 0.3],\n",
        "        marker=dict(\n",
        "        color=['orange', 'green'])\n",
        "             )\n",
        "             ]\n",
        "plot_layout = go.Layout(\n",
        "        xaxis={\"type\": \"category\"},\n",
        "        yaxis={\"title\": \"Churn Rate\"},\n",
        "        title='Churn Rate by total daily charge',\n",
        "        plot_bgcolor  = 'rgb(243,243,243)',\n",
        "        paper_bgcolor  = 'rgb(243,243,243)',\n",
        "    )\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "po.iplot(fig)"
      ],
      "metadata": {
        "id": "obsShutIZW2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_by_international_plan = tele_dataset.groupby('international_plan').churn.mean().reset_index()\n",
        "plot_data = [\n",
        "    go.Bar(\n",
        "        x=plot_by_international_plan['international_plan'],\n",
        "        y=plot_by_international_plan['churn'],\n",
        "        width = [.3,.3],\n",
        "        marker = dict(color=['orange', 'green']) )\n",
        "]\n",
        "\n",
        "plot_layout = go.Layout(\n",
        "    xaxis={'type':'category'},\n",
        "    yaxis={'title':'Churn Rate'},\n",
        "    title = 'Churn by International Plan'\n",
        ")\n",
        "fig = go.Figure(data=plot_data, layout=plot_layout)\n",
        "po.iplot(fig)"
      ],
      "metadata": {
        "id": "7dAKGREkwtzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Onehot encoding for the boolean datasets."
      ],
      "metadata": {
        "id": "SMUKnLLr0Bjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tele_dataset = pd.get_dummies(tele_dataset, columns =[\n",
        "    'international_plan',\n",
        "    'voice_mail_plan'\n",
        "    ],\n",
        "    drop_first = True)"
      ],
      "metadata": {
        "id": "zEgFoVi1wt1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale the features to the same scale"
      ],
      "metadata": {
        "id": "P_1WLvMu3Gkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standardScaler = StandardScaler()\n",
        "columns_for_ft_scaling = ['total_day_minutes', 'total_eve_minutes', 'total_eve_calls', 'total_night_minutes','total_night_calls','account_length']\n",
        "tele_dataset[columns_for_ft_scaling] = standardScaler.fit_transform(tele_dataset[columns_for_ft_scaling])"
      ],
      "metadata": {
        "id": "W_b5cs6H3ngF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encode states with target encoding"
      ],
      "metadata": {
        "id": "ws9fDNhgWbyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "id": "DBdZeTqlCxNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import category_encoders as ce"
      ],
      "metadata": {
        "id": "-PHofd0fCX19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IR9X3-BLgcbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ce_target = ce.TargetEncoder(cols = ['state', 'area_code'])\n",
        "X = tele_dataset.drop('churn', axis = 1)\n",
        "y = tele_dataset['churn']\n",
        "ce_target.fit(X, y)\n",
        "# Must pass the series for y in v1.2.8\n",
        "\n",
        "X = ce_target.transform(X, y)\n"
      ],
      "metadata": {
        "id": "G74A7ntMWpdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "_zrov3eLiLmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the multiple co-linearities"
      ],
      "metadata": {
        "id": "BO4qBd6N1pDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=X.drop(['total_day_minutes', 'total_eve_minutes', 'total_night_minutes','total_intl_minutes', 'voice_mail_plan_1' ], axis = 1)"
      ],
      "metadata": {
        "id": "W-SVt7XR1oU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = y.astype('int')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
      ],
      "metadata": {
        "id": "XiM4aY0jRLbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learning classification model libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "l4Jz5E25SSVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(X_train, y_train)\n",
        "predictions = logmodel.predict(X_test)\n",
        "logmodel_accuracy = round(metrics.accuracy_score(y_test, predictions) * 100, 2)\n",
        "logmodel_accuracy"
      ],
      "metadata": {
        "id": "U8HEwtDLST3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svcmodel = SVC(kernel = 'linear', probability=True, random_state=42)\n",
        "svcmodel.fit(X_train, y_train)\n",
        "svc_predicted = svcmodel.predict(X_test)\n",
        "svc_score= round(metrics.accuracy_score(y_test, svc_predicted) * 100, 2)\n",
        "print(svc_score)"
      ],
      "metadata": {
        "id": "aSWmJuAxkWFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knnmodel = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
        "knnmodel.fit(X_train, y_train)\n",
        "knn_pred = knnmodel.predict(X_test)\n",
        "knn_score= round(metrics.accuracy_score(y_test, knn_pred)*100, 2)\n",
        "print(knn_score)"
      ],
      "metadata": {
        "id": "GABnMB5xlCRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtmodel = DecisionTreeClassifier(random_state=42, criterion = 'gini')\n",
        "dtmodel.fit(X_train, y_train)\n",
        "dt_pred = dtmodel.predict(X_test)\n",
        "dt_score = round(metrics.accuracy_score(y_test, dt_pred)*100,2)\n",
        "print(dt_score)"
      ],
      "metadata": {
        "id": "1tYaeihTlHXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state = 42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_score = round(metrics.accuracy_score(y_test, rf_pred)*100,2)\n",
        "print(rf_score)"
      ],
      "metadata": {
        "id": "6O2ID4r_lNz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda_model = LDA(solver = 'svd', n_components=1)\n",
        "lda_model.fit(X_train, y_train)\n",
        "lda_pred = lda_model.predict(X_test)\n",
        "lda_score = round(metrics.accuracy_score(y_test, lda_pred)*100,2)\n",
        "print(lda_score)\n"
      ],
      "metadata": {
        "id": "IhBcrerdlRmH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}