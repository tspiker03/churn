# -*- coding: utf-8 -*-
"""telecom Churn prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17_pCiLxlNSrCgqDDQ3dvBvbFregt3kfm

Prediction of customer churn of telecom company based on customer behavior
"""

pip install pandas_profiling

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn as sk
import pandas_profiling
import plotly.offline as po
import plotly.graph_objects as go
# %matplotlib inline

pandas_profiling.ProfileReport(pd.read_csv('/train.csv'))

tele_dataset =  pd.read_csv("/train.csv")
tele_dataset.shape

"""Columns: international play, voicemail plan and churn are boolean columns with yes, no answers.  we need to convert to 1,0"""

tele_dataset.loc[tele_dataset.churn=='no','churn'] = 0 
tele_dataset.loc[tele_dataset.churn=='yes','churn'] = 1
tele_dataset.loc[tele_dataset.international_plan=='no','international_plan'] = 0 
tele_dataset.loc[tele_dataset.international_plan=='yes','international_plan'] = 1
tele_dataset.loc[tele_dataset.voice_mail_plan=='no','voice_mail_plan'] = 0 
tele_dataset.loc[tele_dataset.voice_mail_plan=='yes','voice_mail_plan'] = 1

"""Now that that's done, lets look at churn as a function of some of the other variables.  Correlation Matrices aren't perfect for showing exactly which variables are related to churn, but it can give us a ok place to start.  But first, lets look at the overall rate of Churn"""

plot_by_churn_labels = tele_dataset["churn"].value_counts().keys().tolist()
plot_by_churn_values = tele_dataset["churn"].value_counts().values.tolist()

plot_data= [
    go.Pie(labels = plot_by_churn_labels,
           values = plot_by_churn_values,
           marker = dict(colors =  [ 'Teal' ,'Grey'],
                         line = dict(color = "white",
                                     width =  1.5)),
           rotation = 90,
           hoverinfo = "label+value+text",
           hole = .6)
]
plot_layout = go.Layout(dict(title = "Customer Churn",
                   plot_bgcolor  = "rgb(243,243,243)",
                   paper_bgcolor = "rgb(243,243,243)",))


fig = go.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

tele_dataset['churn'].unique

plot_by_day_minutes = tele_dataset.groupby('total_day_minutes').churn.mean().reset_index()
plot_data = [
    go.Bar(
        x=plot_by_day_minutes['total_day_minutes'],
        y=plot_by_day_minutes['churn'],
        width = [0.3, 0.3],
        marker=dict(
        color=['orange', 'green'])
    )
]
plot_layout = go.Layout(
        xaxis={"type": "category"},
        yaxis={"title": "Churn Rate"},
        title='Churn Rate by Total Daily Minutes',
        plot_bgcolor  = 'rgb(243,243,243)',
        paper_bgcolor  = 'rgb(243,243,243)',
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

plot_by_cust_service = tele_dataset.groupby('number_customer_service_calls').churn.mean().reset_index()
plot_data = [
    go.Bar(
        x=plot_by_cust_service['number_customer_service_calls'],
        y=plot_by_cust_service['churn'],
        width = [0.3, 0.3],
        marker=dict(
        color=['orange', 'green'])
    )
]
plot_layout = go.Layout(
        xaxis={"type": "category"},
        yaxis={"title": "Churn Rate"},
        title='Churn Rate by customer service calls',
        plot_bgcolor  = 'rgb(243,243,243)',
        paper_bgcolor  = 'rgb(243,243,243)',
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

plot_by_day_charge = tele_dataset.groupby('total_day_charge').churn.mean().reset_index()
plot_data = [
             go.Bar(
                x=plot_by_day_charge['total_day_charge'],
                y=plot_by_day_charge['churn'],
                width = [0.3, 0.3],
        marker=dict(
        color=['orange', 'green'])
             )
             ]
plot_layout = go.Layout(
        xaxis={"type": "category"},
        yaxis={"title": "Churn Rate"},
        title='Churn Rate by total daily charge',
        plot_bgcolor  = 'rgb(243,243,243)',
        paper_bgcolor  = 'rgb(243,243,243)',
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

plot_by_international_plan = tele_dataset.groupby('international_plan').churn.mean().reset_index()
plot_data = [
    go.Bar(
        x=plot_by_international_plan['international_plan'],
        y=plot_by_international_plan['churn'], 
        width = [.3,.3],
        marker = dict(color=['orange', 'green']) )
]

plot_layout = go.Layout(
    xaxis={'type':'category'},
    yaxis={'title':'Churn Rate'},
    title = 'Churn by International Plan'
)
fig = go.Figure(data=plot_data, layout=plot_layout)
po.iplot(fig)

"""Onehot encoding for the boolean datasets."""

tele_dataset = pd.get_dummies(tele_dataset, columns =[
    'international_plan',
    'voice_mail_plan'
    ],
    drop_first = True)

"""Scale the features to the same scale"""

from sklearn.preprocessing import StandardScaler

standardScaler = StandardScaler()
columns_for_ft_scaling = ['total_day_minutes', 'total_eve_minutes', 'total_eve_calls', 'total_night_minutes','total_night_calls','account_length']
tele_dataset[columns_for_ft_scaling] = standardScaler.fit_transform(tele_dataset[columns_for_ft_scaling])

"""encode states with target encoding"""

pip install category_encoders

import category_encoders as ce



ce_target = ce.TargetEncoder(cols = ['state', 'area_code'])
X = tele_dataset.drop('churn', axis = 1)
y = tele_dataset['churn']
ce_target.fit(X, y)
# Must pass the series for y in v1.2.8

X = ce_target.transform(X, y)

X

"""Drop the multiple co-linearities"""

X=X.drop(['total_day_minutes', 'total_eve_minutes', 'total_night_minutes','total_intl_minutes', 'voice_mail_plan_1' ], axis = 1)

from sklearn.model_selection import train_test_split
y = y.astype('int')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)

# Machine Learning classification model libraries
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

logmodel = LogisticRegression()
logmodel.fit(X_train, y_train)
predictions = logmodel.predict(X_test)
logmodel_accuracy = round(metrics.accuracy_score(y_test, predictions) * 100, 2)
logmodel_accuracy

svcmodel = SVC(kernel = 'linear', probability=True, random_state=42)
svcmodel.fit(X_train, y_train)
svc_predicted = svcmodel.predict(X_test)
svc_score= round(metrics.accuracy_score(y_test, svc_predicted) * 100, 2)
print(svc_score)

from sklearn.neighbors import KNeighborsClassifier
knnmodel = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)
knnmodel.fit(X_train, y_train)
knn_pred = knnmodel.predict(X_test)
knn_score= round(metrics.accuracy_score(y_test, knn_pred)*100, 2)
print(knn_score)

from sklearn.tree import DecisionTreeClassifier
dtmodel = DecisionTreeClassifier(random_state=42, criterion = 'gini')
dtmodel.fit(X_train, y_train)
dt_pred = dtmodel.predict(X_test)
dt_score = round(metrics.accuracy_score(y_test, dt_pred)*100,2)
print(dt_score)

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state = 42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test) 
rf_score = round(metrics.accuracy_score(y_test, rf_pred)*100,2)
print(rf_score)

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
lda_model = LDA(solver = 'svd', n_components=1)
lda_model.fit(X_train, y_train)
lda_pred = lda_model.predict(X_test)
lda_score = round(metrics.accuracy_score(y_test, lda_pred)*100,2) 
print(lda_score)